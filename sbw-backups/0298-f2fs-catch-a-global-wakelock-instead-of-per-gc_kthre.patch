From 2af45ffc6c77e5c55b1d1384f0d9842f2db51d72 Mon Sep 17 00:00:00 2001
From: Park Ju Hyung <qkrwngud825@gmail.com>
Date: Fri, 9 Aug 2019 22:10:02 +0900
Subject: [PATCH 298/420] f2fs: catch a global wakelock instead of per
 gc_kthread

Catching wakelocks per gc_kthread is unnecessary and complicates
create/destroy logic.

Hold a mutex and count GC users instead to catch a global wakelock.
Mutex has been used as gc_wakelock cannot be atomic.

This also fixes stack-use-after-scope causing panics on reading
/sys/kernel/debug/wakeup_sources, first brought to attention by ab123321.

Also, use proper initialize and destroy methods.

Signed-off-by: Park Ju Hyung <qkrwngud825@gmail.com>
---
 fs/f2fs/f2fs.h  |  3 +++
 fs/f2fs/gc.c    | 73 ++++++++++++++++++++++++++++++---------------------------
 fs/f2fs/gc.h    |  3 ---
 fs/f2fs/super.c |  2 ++
 4 files changed, 44 insertions(+), 37 deletions(-)

diff --git a/fs/f2fs/f2fs.h b/fs/f2fs/f2fs.h
index 2e15362e7aec..d5c789dfcd2b 100644
--- a/fs/f2fs/f2fs.h
+++ b/fs/f2fs/f2fs.h
@@ -1389,6 +1389,7 @@ struct f2fs_sb_info {
 	unsigned int cur_victim_sec;		/* current victim section num */
 	unsigned int gc_mode;			/* current GC state */
 	unsigned int next_victim_seg[2];	/* next segment in victim section */
+	unsigned int rapid_gc;			/* is rapid GC running */
 	/* for skip statistic */
 	unsigned int atomic_files;              /* # of opened atomic file */
 	unsigned long long skipped_atomic_files[2];	/* FG_GC and BG_GC */
@@ -3311,6 +3312,8 @@ int f2fs_start_gc_thread(struct f2fs_sb_info *sbi);
 void f2fs_stop_gc_thread(struct f2fs_sb_info *sbi);
 void f2fs_gc_sbi_list_add(struct f2fs_sb_info *sbi);
 void f2fs_gc_sbi_list_del(struct f2fs_sb_info *sbi);
+void __init f2fs_init_rapid_gc(void);
+void __exit f2fs_destroy_rapid_gc(void);
 
 block_t f2fs_start_bidx_of_node(unsigned int node_ofs, struct inode *inode);
 int f2fs_gc(struct f2fs_sb_info *sbi, bool sync, bool background,
diff --git a/fs/f2fs/gc.c b/fs/f2fs/gc.c
index 1bc810eb005f..a4976835d63a 100644
--- a/fs/f2fs/gc.c
+++ b/fs/f2fs/gc.c
@@ -14,6 +14,7 @@
 #include <linux/delay.h>
 #include <linux/freezer.h>
 #include <linux/fb.h>
+#include <linux/pm_wakeup.h>
 #include <linux/power_supply.h>
 
 #include "f2fs.h"
@@ -24,21 +25,28 @@
 
 #define TRIGGER_RAPID_GC (!screen_on && power_supply_is_system_supplied())
 static bool screen_on = true;
+static LIST_HEAD(gc_sbi_list);
+static DEFINE_MUTEX(gc_sbi_mutex);
+static struct wakeup_source gc_wakelock;
 
-static inline void rapid_gc_set_wakelock(struct f2fs_sb_info *sbi,
-		struct f2fs_gc_kthread *gc_th, bool val)
+static inline void rapid_gc_set_wakelock(void)
 {
-	if (val) {
-		if (!gc_th->gc_wakelock.active) {
-			f2fs_info(sbi, "Catching wakelock for rapid GC");
-			__pm_stay_awake(&gc_th->gc_wakelock);
-		}
-	} else {
-		if (gc_th->gc_wakelock.active) {
-			f2fs_info(sbi, "Unlocking wakelock for rapid GC");
-			__pm_relax(&gc_th->gc_wakelock);
-		}
+	struct f2fs_sb_info *sbi;
+	unsigned int set = 0;
+
+	mutex_lock(&gc_sbi_mutex);
+	list_for_each_entry(sbi, &gc_sbi_list, list) {
+		set |= sbi->rapid_gc;
 	}
+
+	if (set && !gc_wakelock.active) {
+		pr_info("F2FS-fs: Catching wakelock for rapid GC");
+		__pm_stay_awake(&gc_wakelock);
+	} else if (!set && gc_wakelock.active) {
+		pr_info("F2FS-fs: Unlocking wakelock for rapid GC");
+		__pm_relax(&gc_wakelock);
+	}
+	mutex_unlock(&gc_sbi_mutex);
 }
 
 static int gc_thread_func(void *data)
@@ -47,7 +55,6 @@ static int gc_thread_func(void *data)
 	struct f2fs_gc_kthread *gc_th = sbi->gc_thread;
 	wait_queue_head_t *wq = &sbi->gc_thread->gc_wait_queue_head;
 	unsigned int wait_ms = gc_th->min_sleep_time;
-	bool rapid_gc;
 
 	set_freezable();
 	do {
@@ -56,14 +63,14 @@ static int gc_thread_func(void *data)
 				gc_th->gc_wake,
 				msecs_to_jiffies(wait_ms));
 
-		rapid_gc = TRIGGER_RAPID_GC;
-		if (rapid_gc) {
-			rapid_gc_set_wakelock(sbi, gc_th, true);
+		sbi->rapid_gc = TRIGGER_RAPID_GC ? 1 : 0;
+		if (sbi->rapid_gc) {
+			rapid_gc_set_wakelock();
 			// Use 1 instead of 0 to allow thread interrupts
 			wait_ms = 1;
 			sbi->gc_mode = GC_URGENT;
 		} else {
-			rapid_gc_set_wakelock(sbi, gc_th, false);
+			rapid_gc_set_wakelock();
 			wait_ms = gc_th->min_sleep_time;
 			sbi->gc_mode = GC_NORMAL;
 		}
@@ -80,7 +87,7 @@ static int gc_thread_func(void *data)
 			break;
 
 		if (sbi->sb->s_writers.frozen >= SB_FREEZE_WRITE) {
-			if (!rapid_gc) {
+			if (!sbi->rapid_gc) {
 				increase_sleep_time(gc_th, &wait_ms);
 				stat_other_skip_bggc_count(sbi);
 			}
@@ -110,8 +117,8 @@ static int gc_thread_func(void *data)
 		 * invalidated soon after by user update or deletion.
 		 * So, I'd like to wait some time to collect dirty segments.
 		 */
-		if (sbi->gc_mode == GC_URGENT || rapid_gc) {
-			if (!rapid_gc)
+		if (sbi->gc_mode == GC_URGENT || sbi->rapid_gc) {
+			if (!sbi->rapid_gc)
 				wait_ms = gc_th->urgent_sleep_time;
 			down_write(&sbi->gc_lock);
 			goto do_gc;
@@ -137,9 +144,10 @@ do_gc:
 		stat_inc_bggc_count(sbi->stat_info);
 
 		/* if return value is not zero, no victim was selected */
-		if (f2fs_gc(sbi, rapid_gc || test_opt(sbi, FORCE_FG_GC), true, NULL_SEGNO)) {
+		if (f2fs_gc(sbi, sbi->rapid_gc || test_opt(sbi, FORCE_FG_GC), true, NULL_SEGNO)) {
 			wait_ms = gc_th->no_gc_sleep_time;
-			rapid_gc_set_wakelock(sbi, gc_th, false);
+			sbi->rapid_gc = false;
+			rapid_gc_set_wakelock();
 			sbi->gc_mode = GC_NORMAL;
 			f2fs_info(sbi,
 				"No more rapid GC victim found, "
@@ -170,7 +178,6 @@ int f2fs_start_gc_thread(struct f2fs_sb_info *sbi)
 	struct f2fs_gc_kthread *gc_th;
 	dev_t dev = sbi->sb->s_bdev->bd_dev;
 	int err = 0;
-	char buf[25];
 
 	if (sbi->gc_thread != NULL)
 		goto out;
@@ -189,13 +196,10 @@ int f2fs_start_gc_thread(struct f2fs_sb_info *sbi)
 	sbi->gc_mode = GC_NORMAL;
 	gc_th->gc_wake= 0;
 
-	snprintf(buf, sizeof(buf), "f2fs_gc-%u:%u", MAJOR(dev), MINOR(dev));
-
-	wakeup_source_init(&gc_th->gc_wakelock, buf);
-
 	sbi->gc_thread = gc_th;
 	init_waitqueue_head(&sbi->gc_thread->gc_wait_queue_head);
-	sbi->gc_thread->f2fs_gc_task = kthread_run(gc_thread_func, sbi, buf);
+	sbi->gc_thread->f2fs_gc_task = kthread_run(gc_thread_func, sbi,
+			"f2fs_gc-%u:%u", MAJOR(dev), MINOR(dev));
 	if (IS_ERR(gc_th->f2fs_gc_task)) {
 		err = PTR_ERR(gc_th->f2fs_gc_task);
 		kvfree(gc_th);
@@ -213,14 +217,11 @@ void f2fs_stop_gc_thread(struct f2fs_sb_info *sbi)
 	if (!gc_th)
 		return;
 	kthread_stop(gc_th->f2fs_gc_task);
-	wakeup_source_trash(&gc_th->gc_wakelock);
 	kvfree(gc_th);
 	sbi->gc_mode = GC_NORMAL;
 	sbi->gc_thread = NULL;
 }
 
-static LIST_HEAD(gc_sbi_list);
-static DEFINE_MUTEX(gc_sbi_mutex);
 /* Trigger rapid GC when invalid block is higher than 3% */
 #define RAPID_GC_LIMIT_INVALID_BLOCK 3
 
@@ -323,14 +324,18 @@ static struct notifier_block fb_notifier_block = {
 	.notifier_call = fb_notifier_callback,
 };
 
-static int __init f2fs_rapid_gc_register_fb(void)
+void __init f2fs_init_rapid_gc(void)
 {
 	INIT_WORK(&rapid_gc_fb_worker, rapid_gc_fb_work);
 	fb_register_client(&fb_notifier_block);
+	wakeup_source_init(&gc_wakelock, "f2fs_rapid_gc_wakelock");
+}
 
-	return 0;
+void __exit f2fs_destroy_rapid_gc(void)
+{
+	fb_unregister_client(&fb_notifier_block);
+	wakeup_source_trash(&gc_wakelock);
 }
-late_initcall(f2fs_rapid_gc_register_fb);
 
 static int select_gc_type(struct f2fs_sb_info *sbi, int gc_type)
 {
diff --git a/fs/f2fs/gc.h b/fs/f2fs/gc.h
index a98ca66c09d1..2bd53eecf398 100644
--- a/fs/f2fs/gc.h
+++ b/fs/f2fs/gc.h
@@ -5,8 +5,6 @@
  * Copyright (c) 2012 Samsung Electronics Co., Ltd.
  *             http://www.samsung.com/
  */
-#include <linux/pm_wakeup.h>
-
 #define GC_THREAD_MIN_WB_PAGES		1	/*
 						 * a threshold to determine
 						 * whether IO subsystem is idle
@@ -27,7 +25,6 @@
 struct f2fs_gc_kthread {
 	struct task_struct *f2fs_gc_task;
 	wait_queue_head_t gc_wait_queue_head;
-	struct wakeup_source gc_wakelock;
 
 	/* for gc sleep time */
 	unsigned int urgent_sleep_time;
diff --git a/fs/f2fs/super.c b/fs/f2fs/super.c
index be6f3a7be09d..c222280c998a 100644
--- a/fs/f2fs/super.c
+++ b/fs/f2fs/super.c
@@ -3677,6 +3677,7 @@ static int __init init_f2fs_fs(void)
 	err = f2fs_init_bioset();
 	if (err)
 		goto free_bio_enrty_cache;
+	f2fs_init_rapid_gc();
 	return 0;
 free_bio_enrty_cache:
 	f2fs_destroy_bio_entry_cache();
@@ -3705,6 +3706,7 @@ fail:
 
 static void __exit exit_f2fs_fs(void)
 {
+	f2fs_destroy_rapid_gc();
 	f2fs_destroy_bioset();
 	f2fs_destroy_bio_entry_cache();
 	f2fs_destroy_post_read_processing();
-- 
2.15.0

